import pandas as pd
from nltk.corpus import stopwords

# تحميل DataFrame من ملف TSV
data = pd.read_csv('C:/Users/Hp/.ir_datasets/antique/collection.tsv', delimiter='\t')

# تحميل الكلمات الوقفية
stop_words = set(stopwords.words('english'))

# إنشاء عمود جديد لكل عمود يحتوي على النصوص
for column_name, column_data in data.items():
    if column_data.dtype == 'O':  # فقط للأعمدة التي يحتوي على النصوص
        column_without_stopwords_name = column_name + '_without_stopwords'
        data[column_without_stopwords_name] = column_data.apply(lambda x: ' '.join([word for word in str(x).split() if not pd.isna(x) and word.lower() not in stop_words]))



/////////////////////////////////////

import pandas as pd
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# تحميل DataFrame من ملف TSV
data = pd.read_csv('C:/Users/Hp/.ir_datasets/antique/collection.tsv', delimiter='\t')

# تحميل الكلمات الوقفية
stop_words = set(stopwords.words('english'))

# إنشاء عمود جديد لكل عمود يحتوي على النصوص
for column_name, column_data in data.items():
    if column_data.dtype == 'O':
        # إنشاء عمود جديد لحفظ النصوص بعد إزالة الكلمات الوقفية وتطبيق التحليل النحوي
        column_without_stopwords_name = column_name + '_without_stopwords'
        data[column_without_stopwords_name] = column_data.apply(lambda x: ' '.join([word for word in word_tokenize(str(x)) if not pd.isna(x) and word.lower() not in stop_words]))

///////////////////////////////////////////

import pandas as pd
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer

# تحميل DataFrame من ملف TSV
data = pd.read_csv('C:/Users/Hp/.ir_datasets/antique/collection.tsv', delimiter='\t')

# تحميل الكلمات الوقفية
stop_words = set(stopwords.words('english'))

# إنشاء عمود جديد لكل عمود يحتوي على النصوص
for column_name, column_data in data.items():
    if column_data.dtype == 'O':
        # إنشاء عمود جديد لحفظ النصوص بعد إزالة الكلمات الوقفية وتطبيق التحليل النحوي
        column_without_stopwords_name = column_name + '_without_stopwords'
        data[column_without_stopwords_name] = column_data.apply(lambda x: ' '.join([PorterStemmer().stem(word) for word in word_tokenize(str(x)) if not pd.isna(x) and word.lower() not in stop_words]))